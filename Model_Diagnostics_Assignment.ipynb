{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model Diagnostics Assignment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/livjab/DS-Unit-2-Sprint-2-Regression/blob/master/Model_Diagnostics_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "pTkoSVmLhAZx"
      },
      "cell_type": "markdown",
      "source": [
        "# Regression Diagnostics\n",
        "\n",
        "The purpose of this assigment is introduce you to a new library for linear regression called statmodels which is much better suited for inferential modeling than sklearn. This assignment is also to familiarize yourself with some of most important procedures for improving the interpretability of regression coefficients. You will also perform important statistical tests that will help establish that whether or not important assumptions that safeguard the interpretability of OLS coefficients have been met. \n",
        "\n",
        "We will continue to use the Ames Housing Dataset so that you can focus on the techniques and not on cleaning/getting associated with a brand new dataset."
      ]
    },
    {
      "metadata": {
        "id": "olp_ShUq9qvc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "from scipy import stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z_gW0Md79-Y1",
        "colab_type": "code",
        "outputId": "dcdd2ce8-fb1a-4b91-e2bd-e1c5b178ad42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/ryanleeallred/datasets/master/Ames%20Housing%20Data/train.csv\")\n",
        "pd.set_option('display.max_columns', None)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>LotConfig</th>\n",
              "      <th>LandSlope</th>\n",
              "      <th>Neighborhood</th>\n",
              "      <th>Condition1</th>\n",
              "      <th>Condition2</th>\n",
              "      <th>BldgType</th>\n",
              "      <th>HouseStyle</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>RoofStyle</th>\n",
              "      <th>RoofMatl</th>\n",
              "      <th>Exterior1st</th>\n",
              "      <th>Exterior2nd</th>\n",
              "      <th>MasVnrType</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>ExterQual</th>\n",
              "      <th>ExterCond</th>\n",
              "      <th>Foundation</th>\n",
              "      <th>BsmtQual</th>\n",
              "      <th>BsmtCond</th>\n",
              "      <th>BsmtExposure</th>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinType2</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>Heating</th>\n",
              "      <th>HeatingQC</th>\n",
              "      <th>CentralAir</th>\n",
              "      <th>Electrical</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <th>KitchenQual</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Functional</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>FireplaceQu</th>\n",
              "      <th>GarageType</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>GarageFinish</th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>GarageQual</th>\n",
              "      <th>GarageCond</th>\n",
              "      <th>PavedDrive</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>196.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>706</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>856</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>856</td>\n",
              "      <td>854</td>\n",
              "      <td>0</td>\n",
              "      <td>1710</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>8</td>\n",
              "      <td>Typ</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2003.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>548</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Veenker</td>\n",
              "      <td>Feedr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>978</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>284</td>\n",
              "      <td>1262</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1976.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>460</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>298</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>162.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Mn</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>486</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>434</td>\n",
              "      <td>920</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>920</td>\n",
              "      <td>866</td>\n",
              "      <td>0</td>\n",
              "      <td>1786</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>608</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Corner</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Crawfor</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>Wd Sdng</td>\n",
              "      <td>Wd Shng</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>BrkTil</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>No</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>216</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>540</td>\n",
              "      <td>756</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>961</td>\n",
              "      <td>756</td>\n",
              "      <td>0</td>\n",
              "      <td>1717</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>7</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Detchd</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>3</td>\n",
              "      <td>642</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>272</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NoRidge</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>350.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Av</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>655</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>490</td>\n",
              "      <td>1145</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1145</td>\n",
              "      <td>1053</td>\n",
              "      <td>0</td>\n",
              "      <td>2198</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>9</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>3</td>\n",
              "      <td>836</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>192</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
              "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
              "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
              "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
              "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
              "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
              "\n",
              "  LandContour Utilities LotConfig LandSlope Neighborhood Condition1  \\\n",
              "0         Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n",
              "1         Lvl    AllPub       FR2       Gtl      Veenker      Feedr   \n",
              "2         Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n",
              "3         Lvl    AllPub    Corner       Gtl      Crawfor       Norm   \n",
              "4         Lvl    AllPub       FR2       Gtl      NoRidge       Norm   \n",
              "\n",
              "  Condition2 BldgType HouseStyle  OverallQual  OverallCond  YearBuilt  \\\n",
              "0       Norm     1Fam     2Story            7            5       2003   \n",
              "1       Norm     1Fam     1Story            6            8       1976   \n",
              "2       Norm     1Fam     2Story            7            5       2001   \n",
              "3       Norm     1Fam     2Story            7            5       1915   \n",
              "4       Norm     1Fam     2Story            8            5       2000   \n",
              "\n",
              "   YearRemodAdd RoofStyle RoofMatl Exterior1st Exterior2nd MasVnrType  \\\n",
              "0          2003     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
              "1          1976     Gable  CompShg     MetalSd     MetalSd       None   \n",
              "2          2002     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
              "3          1970     Gable  CompShg     Wd Sdng     Wd Shng       None   \n",
              "4          2000     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
              "\n",
              "   MasVnrArea ExterQual ExterCond Foundation BsmtQual BsmtCond BsmtExposure  \\\n",
              "0       196.0        Gd        TA      PConc       Gd       TA           No   \n",
              "1         0.0        TA        TA     CBlock       Gd       TA           Gd   \n",
              "2       162.0        Gd        TA      PConc       Gd       TA           Mn   \n",
              "3         0.0        TA        TA     BrkTil       TA       Gd           No   \n",
              "4       350.0        Gd        TA      PConc       Gd       TA           Av   \n",
              "\n",
              "  BsmtFinType1  BsmtFinSF1 BsmtFinType2  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  \\\n",
              "0          GLQ         706          Unf           0        150          856   \n",
              "1          ALQ         978          Unf           0        284         1262   \n",
              "2          GLQ         486          Unf           0        434          920   \n",
              "3          ALQ         216          Unf           0        540          756   \n",
              "4          GLQ         655          Unf           0        490         1145   \n",
              "\n",
              "  Heating HeatingQC CentralAir Electrical  1stFlrSF  2ndFlrSF  LowQualFinSF  \\\n",
              "0    GasA        Ex          Y      SBrkr       856       854             0   \n",
              "1    GasA        Ex          Y      SBrkr      1262         0             0   \n",
              "2    GasA        Ex          Y      SBrkr       920       866             0   \n",
              "3    GasA        Gd          Y      SBrkr       961       756             0   \n",
              "4    GasA        Ex          Y      SBrkr      1145      1053             0   \n",
              "\n",
              "   GrLivArea  BsmtFullBath  BsmtHalfBath  FullBath  HalfBath  BedroomAbvGr  \\\n",
              "0       1710             1             0         2         1             3   \n",
              "1       1262             0             1         2         0             3   \n",
              "2       1786             1             0         2         1             3   \n",
              "3       1717             1             0         1         0             3   \n",
              "4       2198             1             0         2         1             4   \n",
              "\n",
              "   KitchenAbvGr KitchenQual  TotRmsAbvGrd Functional  Fireplaces FireplaceQu  \\\n",
              "0             1          Gd             8        Typ           0         NaN   \n",
              "1             1          TA             6        Typ           1          TA   \n",
              "2             1          Gd             6        Typ           1          TA   \n",
              "3             1          Gd             7        Typ           1          Gd   \n",
              "4             1          Gd             9        Typ           1          TA   \n",
              "\n",
              "  GarageType  GarageYrBlt GarageFinish  GarageCars  GarageArea GarageQual  \\\n",
              "0     Attchd       2003.0          RFn           2         548         TA   \n",
              "1     Attchd       1976.0          RFn           2         460         TA   \n",
              "2     Attchd       2001.0          RFn           2         608         TA   \n",
              "3     Detchd       1998.0          Unf           3         642         TA   \n",
              "4     Attchd       2000.0          RFn           3         836         TA   \n",
              "\n",
              "  GarageCond PavedDrive  WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  \\\n",
              "0         TA          Y           0           61              0          0   \n",
              "1         TA          Y         298            0              0          0   \n",
              "2         TA          Y           0           42              0          0   \n",
              "3         TA          Y           0           35            272          0   \n",
              "4         TA          Y         192           84              0          0   \n",
              "\n",
              "   ScreenPorch  PoolArea PoolQC Fence MiscFeature  MiscVal  MoSold  YrSold  \\\n",
              "0            0         0    NaN   NaN         NaN        0       2    2008   \n",
              "1            0         0    NaN   NaN         NaN        0       5    2007   \n",
              "2            0         0    NaN   NaN         NaN        0       9    2008   \n",
              "3            0         0    NaN   NaN         NaN        0       2    2006   \n",
              "4            0         0    NaN   NaN         NaN        0      12    2008   \n",
              "\n",
              "  SaleType SaleCondition  SalePrice  \n",
              "0       WD        Normal     208500  \n",
              "1       WD        Normal     181500  \n",
              "2       WD        Normal     223500  \n",
              "3       WD       Abnorml     140000  \n",
              "4       WD        Normal     250000  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "kvMIkEnI-aES",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "df = df.fillna(value=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SNlGtnb4-_11",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "target = \"SalePrice\"\n",
        "numeric_columns = df.select_dtypes(include='number').columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uhUueLEM_Ctx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for feature in numeric_columns.drop(target):\n",
        "    sns.scatterplot(x=feature, y=target, data=df, alpha=0.2)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "yb24I_Y0iC4M"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.1 Choose an X and Y variable from your dataset and use them to create a Seaborn Regplot"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "N0NCgQkHie-r",
        "outputId": "ccae268c-53cd-4ee9-eb4e-396fc8616740",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "cell_type": "code",
      "source": [
        "sns.regplot(\"TotRmsAbvGrd\", \"SalePrice\", data=df);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEKCAYAAADEovgeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVABMFEg/kgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "cgbsV7K5igH1"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.2 Now using the X variables that you feel like will be the best predictors of y use statsmodel to run the multiple regression between these variables and Y. You don't need to use every X variable in your dataset, in fact it's probably better if you don't. Just pick ones that you have already cleaned that seem the most relevant to house prices."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ar3WCTGTg5RZ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##### Your Code Here #####\n",
        "\n",
        "target = \"SalePrice\"\n",
        "features = [\"OverallQual\", \"YearBuilt\", \"1stFlrSF\", \"GrLivArea\", \"FullBath\",\n",
        "            \"TotRmsAbvGrd\", \"GarageCars\"]\n",
        "\n",
        "X = df[features]\n",
        "y = df[target]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JkQTHTl-Cnus",
        "colab_type": "code",
        "outputId": "0b9bccc2-7ed8-45a3-d76c-469db3744ecc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "cell_type": "code",
      "source": [
        "model = sm.OLS(y, sm.add_constant(X))\n",
        "results = model.fit()\n",
        "print(results.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:              SalePrice   R-squared:                       0.767\n",
            "Model:                            OLS   Adj. R-squared:                  0.766\n",
            "Method:                 Least Squares   F-statistic:                     681.6\n",
            "Date:                Wed, 01 May 2019   Prob (F-statistic):               0.00\n",
            "Time:                        20:16:27   Log-Likelihood:                -17482.\n",
            "No. Observations:                1460   AIC:                         3.498e+04\n",
            "Df Residuals:                    1452   BIC:                         3.502e+04\n",
            "Df Model:                           7                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "================================================================================\n",
            "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
            "--------------------------------------------------------------------------------\n",
            "const         -8.32e+05   9.07e+04     -9.168      0.000   -1.01e+06   -6.54e+05\n",
            "OverallQual   2.206e+04   1144.021     19.286      0.000    1.98e+04    2.43e+04\n",
            "YearBuilt      382.0298     47.583      8.029      0.000     288.690     475.369\n",
            "1stFlrSF        31.3954      3.305      9.498      0.000      24.911      37.879\n",
            "GrLivArea       52.2235      4.267     12.239      0.000      43.853      60.594\n",
            "FullBath     -7102.4604   2675.734     -2.654      0.008   -1.24e+04   -1853.743\n",
            "TotRmsAbvGrd  -588.2163   1128.778     -0.521      0.602   -2802.425    1625.993\n",
            "GarageCars    1.388e+04   1843.928      7.526      0.000    1.03e+04    1.75e+04\n",
            "==============================================================================\n",
            "Omnibus:                      396.332   Durbin-Watson:                   1.995\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            33263.016\n",
            "Skew:                          -0.010   Prob(JB):                         0.00\n",
            "Kurtosis:                      26.384   Cond. No.                     2.50e+05\n",
            "==============================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 2.5e+05. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
            "  return ptp(axis=axis, out=out, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "6YR3PgK8jA8t"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.3 Identify the standard errors and P-Values of these coefficients in the output table. What is the interpretation of the P-values here?"
      ]
    },
    {
      "metadata": {
        "id": "q3aEPe5MDXoO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "    std err, P>|t|\n",
        "\n",
        "const:\n",
        " - 9.07e+04\n",
        " - 0.000  --> Reject the null hypothesis. This feature is a meaningful addtion to the model.\n",
        "\n",
        "OverallQual:\n",
        "- 1144.021\n",
        "- 0.000 --> Reject the null hypothesis. This feature is a meaningful addtion to the model.\n",
        "\n",
        "YearBuilt:\n",
        "- 47.583\n",
        "- 0.000 --> Reject the null hypothesis. This feature is a meaningful addtion to the model.\n",
        "\n",
        "1stFlrSF:\n",
        "- 3.305\n",
        "- 0.000 --> Reject the null hypothesis. This feature is a meaningful addtion to the model. \n",
        "\n",
        "GrLivArea:\n",
        "- 4.267\n",
        "- 0.000 --> Reject the null hypothesis. This feature is a meaningful addtion to the model.\n",
        "\n",
        "FullBath:\n",
        "- 2675.734\n",
        "- 0.008 --> Reject the null hypothesis. This feature is a meaningful addtion to the model.\n",
        "\n",
        "TotRmsAbvGrd:\n",
        "- 1128.778\n",
        "- 0.602  --> Fail to reject the null hypothesis. This feature is not a meaningful addtion to the model.\n",
        "\n",
        "GarageCars:\n",
        "- 1843.928\n",
        "- 0.000 --> Reject the null hypothesis. This feature is a meaningful addtion to the model."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "6DREQUkmjQKM"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.4 Remove outliers from your dataset and run the regression again. Do you see a change in some coefficients? Which seem to move the most?"
      ]
    },
    {
      "metadata": {
        "id": "RlKETn6zIFSw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "df = df[(np.abs(stats.zscore(df)) < 3).all(axis=1)]\n",
        "print(df.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a6mWtcScIJds",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# I'm assuming my df is not clean enough for the aboe code to work, so I'll stick\n",
        "# with the columns I've already been using."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-i1D8uJAHKSn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cleaned_df = df[[\"OverallQual\", \"YearBuilt\", \"1stFlrSF\", \"GrLivArea\", \"FullBath\",\n",
        "            \"TotRmsAbvGrd\", \"GarageCars\", \"SalePrice\"]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "K6yJ9c12jXvC",
        "outputId": "8abc923c-d260-48d9-8f4f-19f228ea86aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(cleaned_df.shape)\n",
        "cleaned_df = cleaned_df[(np.abs(stats.zscore(cleaned_df)) < 3).all(axis=1)]\n",
        "print(cleaned_df.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1411, 8)\n",
            "(1366, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4MzA4tNwKByR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "features = [\"OverallQual\", \"YearBuilt\", \"1stFlrSF\", \"GrLivArea\", \"FullBath\",\n",
        "            \"TotRmsAbvGrd\", \"GarageCars\"]\n",
        "target = 'SalePrice'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QQhgVegXIZCY",
        "colab_type": "code",
        "outputId": "52cb1245-01bf-417a-909d-a89ef9d98901",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "cell_type": "code",
      "source": [
        "X = cleaned_df[features]\n",
        "y = cleaned_df[target]\n",
        "\n",
        "model = sm.OLS(y, sm.add_constant(X))\n",
        "results = model.fit()\n",
        "print(results.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:              SalePrice   R-squared:                       0.809\n",
            "Model:                            OLS   Adj. R-squared:                  0.808\n",
            "Method:                 Least Squares   F-statistic:                     821.4\n",
            "Date:                Wed, 01 May 2019   Prob (F-statistic):               0.00\n",
            "Time:                        20:49:10   Log-Likelihood:                -15857.\n",
            "No. Observations:                1366   AIC:                         3.173e+04\n",
            "Df Residuals:                    1358   BIC:                         3.177e+04\n",
            "Df Model:                           7                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "================================================================================\n",
            "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
            "--------------------------------------------------------------------------------\n",
            "const        -8.753e+05   6.87e+04    -12.747      0.000   -1.01e+06   -7.41e+05\n",
            "OverallQual   1.766e+04    876.432     20.153      0.000    1.59e+04    1.94e+04\n",
            "YearBuilt      421.5300     36.059     11.690      0.000     350.792     492.268\n",
            "1stFlrSF        31.7136      2.538     12.497      0.000      26.735      36.692\n",
            "GrLivArea       60.8221      3.439     17.688      0.000      54.076      67.568\n",
            "FullBath     -7307.2792   1977.175     -3.696      0.000   -1.12e+04   -3428.631\n",
            "TotRmsAbvGrd -3180.6921    877.178     -3.626      0.000   -4901.463   -1459.922\n",
            "GarageCars    9971.3591   1377.954      7.236      0.000    7268.210    1.27e+04\n",
            "==============================================================================\n",
            "Omnibus:                       53.154   Durbin-Watson:                   2.024\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              153.762\n",
            "Skew:                           0.000   Prob(JB):                     4.08e-34\n",
            "Kurtosis:                       4.644   Cond. No.                     2.58e+05\n",
            "==============================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 2.58e+05. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
            "  return ptp(axis=axis, out=out, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "R6v-lirWKr7I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The coefficient for TotRmsAbvGrd changed the most between the two tests. This was the feature with the highest p value in the first run, and once the outliers have been removed, it is now made more relevent to the model."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "YR2zFM3ajX2O"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.5 Create a new log(y) variable and use it to run a log-linear regression of your variables using statmodels "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "G3ISRRvwjwkr",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df['ln_price'] = np.log(df[\"SalePrice\"])\n",
        "df = df.drop(columns=\"SalePrice\")\n",
        "\n",
        "target = 'ln_price'\n",
        "features = df.columns.drop(target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pe8MezVCMHpK",
        "colab_type": "code",
        "outputId": "9813524a-13a0-45a7-ea14-58fc8ae078d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        }
      },
      "cell_type": "code",
      "source": [
        "X = df[features] \n",
        "y = df[target]\n",
        "model = sm.OLS(y, sm.add_constant(X))\n",
        "results = model.fit()\n",
        "print(results.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
            "  return ptp(axis=axis, out=out, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-62d7399c88b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/statsmodels/regression/linear_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    815\u001b[0m                  **kwargs):\n\u001b[1;32m    816\u001b[0m         super(OLS, self).__init__(endog, exog, missing=missing,\n\u001b[0;32m--> 817\u001b[0;31m                                   hasconst=hasconst, **kwargs)\n\u001b[0m\u001b[1;32m    818\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"weights\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"weights\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/statsmodels/regression/linear_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, weights, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m         super(WLS, self).__init__(endog, exog, missing=missing,\n\u001b[0;32m--> 663\u001b[0;31m                                   weights=weights, hasconst=hasconst, **kwargs)\n\u001b[0m\u001b[1;32m    664\u001b[0m         \u001b[0mnobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/statsmodels/regression/linear_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \"\"\"\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRegressionModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_attr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pinv_wexog'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wendog'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wexog'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLikelihoodModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mhasconst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hasconst'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         self.data = self._handle_data(endog, exog, missing, hasconst,\n\u001b[0;32m---> 64\u001b[0;31m                                       **kwargs)\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_constant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_constant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36m_handle_data\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhasconst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhasconst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;31m# kwargs arrays could have changed, easier to just attach here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/statsmodels/base/data.py\u001b[0m in \u001b[0;36mhandle_data\u001b[0;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m     \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_data_class_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m     return klass(endog, exog=exog, missing=missing, hasconst=hasconst,\n\u001b[0;32m--> 633\u001b[0;31m                  **kwargs)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/statsmodels/base/data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_endog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mendog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_exog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_endog_exog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# this has side-effects, attaches k_constant and const_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/statsmodels/base/data.py\u001b[0m in \u001b[0;36m_convert_endog_exog\u001b[0;34m(self, endog, exog)\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0mexog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexog\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mexog\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mendog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mexog\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m             raise ValueError(\"Pandas data cast to numpy dtype of object. \"\n\u001b[0m\u001b[1;32m    475\u001b[0m                              \"Check input data with np.asarray(data).\")\n\u001b[1;32m    476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPandasData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_endog_exog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Pandas data cast to numpy dtype of object. Check input data with np.asarray(data)."
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "PVRSM3p1jwyu"
      },
      "cell_type": "markdown",
      "source": [
        "## 2.1 Run a test for high levels of collinearity in your dataset. Calculate the Variance Inflation Factor for each X variable. Do you see VIF values greater than ten? If so try omitting those X variables and run your regression again. Do the standard errors change? Do the coefficients change? Do the coefficients seem to have an interpretation that matches your intuition?"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "I_Q9_rx6kQzM",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##### Your Code Here #####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "I7EJafYokQ9Z"
      },
      "cell_type": "markdown",
      "source": [
        "## 2.2 Variables that have high levels of multicollinearity should also be highly correlated with each other. Calculate your X matrix's correlation matrix to check if the variables highlighted by the VIF test truly are highly correlated."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "sxOW6Y5EkoCG",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##### Your Code Here #####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "pekJWvLzkoRu"
      },
      "cell_type": "markdown",
      "source": [
        "## 2.3 If you have variables with high Variance Inflation Factors, try excluding them from your regression. Do your standard errors improve? (get smaller). If high levels of multicollinearity are removed, the precision of the dataset should increase."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3RsG6Fo2p1v7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##### Your Code Here #####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "AH_XQh5mp1E2"
      },
      "cell_type": "markdown",
      "source": [
        "## 2.4 Recalculate your regression using Robust Standard Errors? What happens to your standard errors?"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "JdQ3N-vRktaY",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##### Your Code Here #####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Bsq_CRqOpBSy"
      },
      "cell_type": "markdown",
      "source": [
        "## 2.5 Use scatterplots or Seaborn's pairplot functionality to perform an eyeball test for potential variables that would be candidates for generating polynomial regressors. "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jGkD_XIBpcSj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##### Your Code Here #####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Tg3nQP3YpcxJ"
      },
      "cell_type": "markdown",
      "source": [
        "## 2.6 Use seaborn's residplot to plot the distribution of each x variable's residuals. Does these plots indicate any other features that would be potential candidates for polynomial features."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "d7EDAAI0psaE",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##### Your Code Here #####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "W0Y0wPNAps68"
      },
      "cell_type": "markdown",
      "source": [
        "## 2.6 Feature Engineer the appropriate polynomial features from your analysis above and include them in one final log-polynomial, robust standard error, regression. Do the coefficients of this most advanced regression match your intuition better than the coefficients of the very first regression that we ran with the Statmodels library?"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "eaPcNaNaqVAj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##### Your Code Here #####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "MaNLIAtW9XDp"
      },
      "cell_type": "markdown",
      "source": [
        "# Stretch Goals\n",
        "\n",
        "- Research the assumptions that are required for OLS to be BLUE the \"Best Linear Unbiased Estimator\". You might try searching and trying to understand the conditions of what's called the Gauss-Markov Theorem.\n",
        "- Research other diagnostic tests. Can you show that residuals are normally distributed graphically?\n",
        "- Write a blog post about inferential modeling using linear regression."
      ]
    }
  ]
}